{% extends "base.html" %}

{% block title %}Báo cáo khoa học{% endblock %}

{% block extra_css %}
<!-- MathJax for rendering mathematical formulas -->
<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [['$','$'], ['\\(','\\)']],
      displayMath: [['$$','$$'], ['\\[','\\]']],
      processEscapes: true
    },
    CommonHTML: { linebreaks: { automatic: true } },
    "HTML-CSS": { linebreaks: { automatic: true } },
    SVG: { linebreaks: { automatic: true } }
  });
</script>

<style>
    /* Styling for scientific report */
    .report-section {
        margin-bottom: 2.5rem;
    }

    .report-title {
        color: #343a40;
        border-bottom: 2px solid #007bff;
        padding-bottom: 0.5rem;
        margin-bottom: 1.5rem;
    }

    .section-title {
        color: #007bff;
        margin-top: 1.5rem;
        margin-bottom: 1rem;
        font-weight: 600;
    }

    .subsection-title {
        color: #28a745;
        margin-top: 1.2rem;
        margin-bottom: 0.8rem;
        font-weight: 500;
    }

    .report-content {
        text-align: justify;
        line-height: 1.6;
    }

    .report-content p {
        margin-bottom: 1rem;
    }

    .report-image {
        margin: 1.5rem 0;
        box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
        border-radius: 5px;
    }

    .report-table {
        margin: 1.5rem 0;
    }

    .report-table th {
        background-color: #f8f9fa;
    }

    .report-note {
        background-color: #f8f9fa;
        border-left: 4px solid #007bff;
        padding: 1rem;
        margin: 1.5rem 0;
    }

    .report-formula {
        background-color: #f8f9fa;
        padding: 1rem;
        margin: 1rem 0;
        border-radius: 5px;
        text-align: center;
    }

    .feature-item {
        background-color: #f8f9fa;
        border-radius: 5px;
        padding: 1rem;
        margin-bottom: 1rem;
        border-left: 3px solid #28a745;
    }

    .feature-item h5 {
        color: #28a745;
        margin-bottom: 0.5rem;
    }

    .highlight {
        background-color: #fff3cd;
        padding: 0.2rem 0.4rem;
        border-radius: 3px;
    }

    .reference {
        font-size: 0.9rem;
        color: #6c757d;
        margin-top: 2rem;
        padding-top: 1rem;
        border-top: 1px solid #dee2e6;
    }

    .reference ol {
        padding-left: 1.5rem;
    }

    .reference li {
        margin-bottom: 0.5rem;
    }

    /* Table styling for feature maps */
    .feature-table {
        width: 100%;
        margin-bottom: 1rem;
        background-color: #fff;
        border-collapse: collapse;
    }

    .feature-table th,
    .feature-table td {
        padding: 0.75rem;
        text-align: center;
        border: 1px solid #dee2e6;
    }

    .feature-table th {
        background-color: #f8f9fa;
        font-weight: 600;
    }

    .feature-table tr:nth-child(even) {
        background-color: #f8f9fa;
    }

    /* Styling for code blocks */
    .code-block {
        background-color: #f8f9fa;
        border-left: 4px solid #6c757d;
        padding: 1rem;
        margin: 1rem 0;
        font-family: 'Courier New', monospace;
        overflow-x: auto;
    }
</style>
{% endblock %}

{% block content %}
<div class="container report-content">
    <h1 class="text-center report-title">Báo cáo khoa học về nhận diện khách hàng trong hệ thống chatbot bán hàng</h1>

    <!-- Phần giới thiệu -->
    <section class="report-section" id="introduction">
        <h2 class="section-title">Giới thiệu</h2>
        <p>
            Trong thời đại số hóa hiện nay, các hệ thống chatbot bán hàng đang ngày càng phổ biến, giúp doanh nghiệp tự động hóa quy trình bán hàng và hỗ trợ khách hàng. Tuy nhiên, một trong những thách thức lớn nhất của các hệ thống này là khả năng nhận diện và cá nhân hóa trải nghiệm cho từng khách hàng. Công nghệ nhận diện khuôn mặt đóng vai trò quan trọng trong việc giải quyết thách thức này, cho phép hệ thống chatbot nhận diện khách hàng quen thuộc và cung cấp trải nghiệm mua sắm được cá nhân hóa.
        </p>
        <p>
            <strong>Nhận diện khách hàng</strong> trong hệ thống chatbot bán hàng thường bao gồm hai giai đoạn chính: phát hiện khuôn mặt (face detection) và nhận dạng khuôn mặt (face recognition). Quá trình này cho phép hệ thống xác định danh tính của khách hàng, truy xuất lịch sử mua hàng và sở thích cá nhân, từ đó cung cấp dịch vụ tư vấn và đề xuất sản phẩm phù hợp.
        </p>
        <p>
            <strong>Phát hiện khuôn mặt</strong> là bước đầu tiên và quan trọng, nhằm xác định vị trí và kích thước của khuôn mặt trong ảnh hoặc video từ webcam của khách hàng. Độ chính xác của bước này ảnh hưởng trực tiếp đến hiệu suất của toàn bộ hệ thống nhận diện. Các thuật toán phát hiện khuôn mặt hiện đại như RetinaFace, MTCNN, YOLO và Haar Cascade đã đạt được những tiến bộ đáng kể về độ chính xác và tốc độ xử lý, phù hợp cho các ứng dụng thương mại điện tử.
        </p>
        <p>
            <strong>Nhận dạng khuôn mặt</strong> là bước tiếp theo, nhằm xác định danh tính của khách hàng dựa trên khuôn mặt đã được phát hiện. Các phương pháp nhận dạng khuôn mặt hiện đại như ArcFace sử dụng các mô hình học sâu để trích xuất các đặc trưng khuôn mặt và so sánh chúng với cơ sở dữ liệu khách hàng đã đăng ký.
        </p>
        <p>
            Trong báo cáo này, chúng tôi trình bày một hệ thống toàn diện về nhận diện khách hàng trong chatbot bán hàng, tập trung vào việc tích hợp các công nghệ nhận diện khuôn mặt tiên tiến (RetinaFace và ArcFace) với hệ thống chatbot thông minh để nâng cao trải nghiệm mua sắm trực tuyến và tăng hiệu quả bán hàng.
        </p>
    </section>

    <!-- Phần phát hiện khuôn mặt trong hệ thống chatbot bán hàng -->
    <section class="report-section" id="face-detection-ecommerce">
        <h2 class="section-title">Phát hiện khuôn mặt khách hàng trong hệ thống chatbot bán hàng</h2>

        <p>
            Trong hệ thống chatbot bán hàng, việc phát hiện chính xác khuôn mặt khách hàng là bước đầu tiên và quan trọng trong quá trình nhận diện khách hàng. Khi khách hàng tương tác với chatbot thông qua webcam, hệ thống cần nhanh chóng và chính xác xác định vị trí khuôn mặt trong khung hình, ngay cả trong điều kiện ánh sáng không lý tưởng hoặc góc nhìn khác nhau.
        </p>

        <p>
            Chúng tôi đã lựa chọn RetinaFace làm nền tảng cho hệ thống phát hiện khuôn mặt trong chatbot bán hàng của mình vì hiệu suất vượt trội của nó trong các điều kiện thực tế. Dưới đây là chi tiết về kiến trúc và cách triển khai RetinaFace trong hệ thống của chúng tôi.
        </p>

        <h3 class="subsection-title">1. Kiến trúc RetinaFace cho ứng dụng thương mại điện tử</h3>

        <h4 class="subsection-title">1.1 Backbone và Feature Pyramid tối ưu cho webcam</h4>
        <p>
            Để đảm bảo hiệu suất thời gian thực trên các thiết bị của khách hàng, chúng tôi đã tối ưu hóa RetinaFace bằng cách sử dụng MobileNet làm backbone thay vì ResNet nặng hơn. Kiến trúc Feature Pyramid Network (FPN) được giữ nguyên để đảm bảo khả năng phát hiện khuôn mặt ở nhiều kích thước khác nhau - điều cần thiết khi khách hàng di chuyển gần hoặc xa webcam:
        </p>

        <div class="table-responsive">
            <table class="table feature-table">
                <thead>
                    <tr>
                        <th>Feature Map</th>
                        <th>Kích thước đầu ra (cho ảnh 640×640)</th>
                        <th>Ứng dụng trong thương mại điện tử</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>P2 (160×160×256)</td>
                        <td>Stride: 4, Anchors: 16-25px</td>
                        <td>Phát hiện khuôn mặt khi khách hàng ở xa webcam</td>
                    </tr>
                    <tr>
                        <td>P3 (80×80×256)</td>
                        <td>Stride: 8, Anchors: 32-50px</td>
                        <td>Phát hiện khuôn mặt ở khoảng cách trung bình</td>
                    </tr>
                    <tr>
                        <td>P4 (40×40×256)</td>
                        <td>Stride: 16, Anchors: 64-101px</td>
                        <td>Phát hiện khuôn mặt ở khoảng cách gần</td>
                    </tr>
                    <tr>
                        <td>P5-P6</td>
                        <td>Stride: 32-64, Anchors: 128-406px</td>
                        <td>Phát hiện khi khách hàng rất gần webcam (hiếm gặp)</td>
                    </tr>
                </tbody>
            </table>
        </div>

        <div class="feature-item">
            <h5>Tối ưu hóa cho ứng dụng thương mại điện tử:</h5>
            <ul>
                <li>Tập trung 75% anchors trên P2-P3 để xử lý khoảng cách phổ biến khi khách hàng sử dụng máy tính.</li>
                <li>Giảm độ phức tạp tính toán bằng cách sử dụng MobileNet để đảm bảo trải nghiệm mượt mà trên thiết bị của khách hàng.</li>
                <li>Tối ưu hóa thời gian xử lý để giảm độ trễ trong tương tác với chatbot.</li>
            </ul>
        </div>

        <h4 class="subsection-title">1.2 Các nhánh dự đoán đa nhiệm vụ cho nhận diện khách hàng</h4>
        <p>
            Mô hình RetinaFace trong hệ thống chatbot bán hàng của chúng tôi thực hiện 4 nhánh dự đoán song song, mỗi nhánh đóng vai trò quan trọng trong việc nhận diện chính xác khách hàng:
        </p>

        <div class="row">
            <div class="col-md-6">
                <div class="feature-item">
                    <h5>1. Phân loại khuôn mặt:</h5>
                    <ul>
                        <li>Xác định có phải khuôn mặt hay không - loại bỏ các vùng không phải khuôn mặt.</li>
                        <li>Đảm bảo chatbot chỉ tương tác khi phát hiện được khuôn mặt khách hàng.</li>
                    </ul>
                </div>
            </div>
            <div class="col-md-6">
                <div class="feature-item">
                    <h5>2. Xác định vùng khuôn mặt:</h5>
                    <ul>
                        <li>Dự đoán chính xác vị trí và kích thước khuôn mặt (tx, ty, tw, th).</li>
                        <li>Cắt chính xác vùng khuôn mặt để chuyển sang bước nhận dạng.</li>
                    </ul>
                </div>
            </div>
        </div>

        <div class="row">
            <div class="col-md-6">
                <div class="feature-item">
                    <h5>3. Xác định điểm mốc khuôn mặt:</h5>
                    <ul>
                        <li>Dự đoán 5 điểm mốc: 2 mắt, mũi, 2 khóe miệng.</li>
                        <li>Cho phép căn chỉnh khuôn mặt trước khi nhận dạng, cải thiện độ chính xác.</li>
                        <li>Hỗ trợ phát hiện góc nghiêng của khuôn mặt khách hàng.</li>
                    </ul>
                </div>
            </div>
            <div class="col-md-6">
                <div class="feature-item">
                    <h5>4. Phân tích hình học 3D (tùy chọn):</h5>
                    <ul>
                        <li>Dự đoán thông tin 3D của khuôn mặt để cải thiện khả năng nhận diện trong điều kiện ánh sáng kém.</li>
                        <li>Hỗ trợ phát hiện khuôn mặt thật (anti-spoofing) - ngăn chặn giả mạo bằng ảnh.</li>
                        <li>Có thể tắt trên thiết bị yếu để tối ưu hiệu suất.</li>
                    </ul>
                </div>
            </div>
        </div>

        <div class="report-note">
            <p class="mb-0">Tất cả các nhánh sử dụng cùng một feature extractor chia sẻ, giúp tối ưu hóa hiệu suất tính toán - yếu tố quan trọng để đảm bảo trải nghiệm mượt mà cho khách hàng khi tương tác với chatbot bán hàng.</p>
        </div>

        <h3 class="subsection-title">2. Quy trình xử lý trong thời gian thực</h3>

        <p>
            Khi khách hàng tương tác với chatbot bán hàng thông qua webcam, hệ thống thực hiện quy trình phát hiện khuôn mặt theo các bước sau:
        </p>

        <ol>
            <li><strong>Tiền xử lý hình ảnh:</strong> Chuẩn hóa kích thước (640×640px), điều chỉnh độ sáng và độ tương phản để thích ứng với điều kiện ánh sáng khác nhau.</li>
            <li><strong>Trích xuất đặc trưng:</strong> Hình ảnh đi qua MobileNet và FPN để tạo ra các feature map đa tỷ lệ.</li>
            <li><strong>Phát hiện và lọc:</strong> Áp dụng ngưỡng tin cậy (confidence threshold) 0.8 để loại bỏ các phát hiện không chắc chắn, đảm bảo độ chính xác.</li>
            <li><strong>Xử lý chồng chéo:</strong> Áp dụng Non-Maximum Suppression với ngưỡng IoU 0.4 để loại bỏ các box chồng chéo.</li>
            <li><strong>Căn chỉnh khuôn mặt:</strong> Sử dụng 5 điểm mốc để căn chỉnh khuôn mặt về vị trí chuẩn trước khi chuyển sang bước nhận dạng.</li>
        </ol>

        <h4 class="subsection-title">2.1 Tối ưu hóa hiệu suất cho ứng dụng thương mại điện tử</h4>

        <p>
            Để đảm bảo trải nghiệm mượt mà cho khách hàng khi tương tác với chatbot bán hàng, chúng tôi đã thực hiện các tối ưu hóa sau:
        </p>

        <div class="row">
            <div class="col-md-6">
                <div class="feature-item">
                    <h5>Tối ưu hóa tốc độ:</h5>
                    <ul>
                        <li>Giảm tần suất phát hiện xuống 10 khung hình/giây - đủ cho tương tác nhưng giảm tải CPU/GPU.</li>
                        <li>Sử dụng phiên bản MobileNet nhẹ hơn cho thiết bị có cấu hình thấp.</li>
                        <li>Tắt nhánh Dense 3D Mesh Regression trên thiết bị yếu.</li>
                    </ul>
                </div>
            </div>
            <div class="col-md-6">
                <div class="feature-item">
                    <h5>Tối ưu hóa độ chính xác:</h5>
                    <ul>
                        <li>Áp dụng kỹ thuật tăng cường dữ liệu (data augmentation) để cải thiện khả năng thích ứng với điều kiện ánh sáng khác nhau.</li>
                        <li>Sử dụng bộ nhớ đệm để theo dõi vị trí khuôn mặt qua các khung hình, giảm thiểu hiện tượng nhấp nháy.</li>
                        <li>Tích hợp cơ chế phát hiện chất lượng khuôn mặt để thông báo cho khách hàng khi điều kiện không lý tưởng.</li>
                    </ul>
                </div>
            </div>
        </div>

        <div class="report-formula">
            $$\mathcal{L}_{total} = \mathcal{L}_{cls} + \lambda_1 \cdot \mathcal{L}_{box} + \lambda_2 \cdot \mathcal{L}_{landmark} + \lambda_3 \cdot \mathcal{L}_{dense}$$
        </div>

        <p>
            Trong đó các hệ số $\lambda$ được điều chỉnh để ưu tiên độ chính xác của box và landmark - hai yếu tố quan trọng nhất cho việc nhận diện khách hàng trong hệ thống chatbot bán hàng.
        </p>
    </section>

    <!-- Phần đánh giá giữa các mô hình -->
    <section class="report-section" id="model-comparison">
        <h2 class="section-title">Đánh giá hiệu suất giữa các mô hình phát hiện khuôn mặt</h2>
        <p>
            Trong phần này, chúng tôi sẽ so sánh hiệu suất của RetinaFace với các mô hình phát hiện khuôn mặt phổ biến khác như MTCNN, Haar Cascade và YOLO dựa trên các chỉ số đánh giá quan trọng.
        </p>

        <h3 class="subsection-title">Các chỉ số đánh giá</h3>
        <p>
            Để đánh giá hiệu suất của các mô hình phát hiện khuôn mặt, chúng tôi sử dụng ba chỉ số chính:
        </p>

        <div class="row">
            <div class="col-md-4">
                <div class="feature-item">
                    <h5>IoU (Intersection over Union)</h5>
                    <p>Đo lường độ chính xác của bounding box dự đoán so với ground truth. Giá trị IoU càng cao càng tốt, thể hiện sự trùng khớp giữa vùng dự đoán và vùng thực tế.</p>
                </div>
            </div>
            <div class="col-md-4">
                <div class="feature-item">
                    <h5>Khoảng cách tâm</h5>
                    <p>Đo lường khoảng cách Euclidean giữa tâm của bounding box dự đoán và tâm của ground truth. Giá trị càng thấp càng tốt, thể hiện vị trí dự đoán gần với vị trí thực tế.</p>
                </div>
            </div>
            <div class="col-md-4">
                <div class="feature-item">
                    <h5>Thời gian xử lý</h5>
                    <p>Đo lường thời gian cần thiết để mô hình phát hiện khuôn mặt trong một ảnh. Giá trị càng thấp càng tốt, thể hiện hiệu suất xử lý nhanh hơn.</p>
                </div>
            </div>
        </div>

        <h3 class="subsection-title">Kết quả so sánh hiệu suất</h3>
        <p>
            Dựa trên các thử nghiệm trên tập dữ liệu của chúng tôi, kết quả so sánh hiệu suất giữa các mô hình được tóm tắt trong bảng toàn diện dưới đây:
        </p>

        <div class="table-responsive">
            <table class="table feature-table">
                <thead>
                    <tr>
                        <th rowspan="2">Mô hình</th>
                        <th colspan="3">Chỉ số hiệu suất chính</th>
                        <th colspan="2">Phân tích lỗi</th>
                        <th colspan="2">Đánh giá tổng quan</th>
                    </tr>
                    <tr>
                        <th>IoU trung bình</th>
                        <th>Khoảng cách tâm (px)</th>
                        <th>Thời gian xử lý (ms)</th>
                        <th>IoU = 0</th>
                        <th>0 < IoU < 0.5</th>
                        <th>Ưu điểm</th>
                        <th>Nhược điểm</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><strong>RetinaFace</strong></td>
                        <td>0.89</td>
                        <td>12.5</td>
                        <td>180</td>
                        <td>3%</td>
                        <td>5%</td>
                        <td>Độ chính xác cao nhất, phát hiện tốt khuôn mặt nhỏ và bị che khuất</td>
                        <td>Thời gian xử lý lâu nhất, yêu cầu tài nguyên tính toán cao</td>
                    </tr>
                    <tr>
                        <td><strong>MTCNN</strong></td>
                        <td>0.82</td>
                        <td>15.3</td>
                        <td>120</td>
                        <td>5%</td>
                        <td>8%</td>
                        <td>Cân bằng giữa độ chính xác và tốc độ, phát hiện tốt landmark</td>
                        <td>Khó phát hiện khuôn mặt ở góc nghiêng lớn</td>
                    </tr>
                    <tr>
                        <td><strong>YOLO</strong></td>
                        <td>0.85</td>
                        <td>14.2</td>
                        <td>90</td>
                        <td>4%</td>
                        <td>7%</td>
                        <td>Tốc độ nhanh, phát hiện tốt nhiều khuôn mặt cùng lúc</td>
                        <td>Độ chính xác thấp hơn RetinaFace, đặc biệt với khuôn mặt nhỏ</td>
                    </tr>
                    <tr>
                        <td><strong>Haar Cascade</strong></td>
                        <td>0.75</td>
                        <td>18.7</td>
                        <td>45</td>
                        <td>8%</td>
                        <td>12%</td>
                        <td>Tốc độ nhanh nhất, yêu cầu tài nguyên thấp</td>
                        <td>Độ chính xác thấp nhất, dễ bị ảnh hưởng bởi điều kiện ánh sáng</td>
                    </tr>
                </tbody>
            </table>
        </div>

        <p>
            <strong>Chú thích:</strong>
            <ul>
                <li><strong>IoU trung bình:</strong> Độ chính xác trung bình của bounding box dự đoán so với ground truth.</li>
                <li><strong>Khoảng cách tâm:</strong> Khoảng cách Euclidean trung bình giữa tâm của bounding box dự đoán và ground truth.</li>
                <li><strong>IoU = 0:</strong> Tỷ lệ ảnh mà mô hình không phát hiện được khuôn mặt.</li>
                <li><strong>0 < IoU < 0.5:</strong> Tỷ lệ ảnh mà mô hình phát hiện khuôn mặt nhưng với độ chính xác thấp.</li>
            </ul>
        </p>

        <h3 class="subsection-title">Phân tích kết quả</h3>
        <p>
            Từ kết quả so sánh trên, chúng ta có thể rút ra một số nhận xét quan trọng:
        </p>

        <ul>
            <li><strong>RetinaFace</strong> đạt hiệu suất cao nhất về độ chính xác (IoU = 0.89) nhưng đòi hỏi thời gian xử lý lâu nhất (180ms). Mô hình này phù hợp cho các ứng dụng yêu cầu độ chính xác cao và không quá nhạy cảm về thời gian xử lý.</li>
            <li><strong>MTCNN</strong> cung cấp sự cân bằng tốt giữa độ chính xác và tốc độ, phù hợp cho nhiều ứng dụng thực tế.</li>
            <li><strong>YOLO</strong> có tốc độ xử lý nhanh hơn đáng kể so với RetinaFace và MTCNN, trong khi vẫn duy trì độ chính xác khá tốt, phù hợp cho các ứng dụng thời gian thực.</li>
            <li><strong>Haar Cascade</strong> có tốc độ nhanh nhất nhưng độ chính xác thấp nhất, phù hợp cho các ứng dụng có tài nguyên tính toán hạn chế và không yêu cầu độ chính xác cao.</li>
        </ul>
    </section>

    <!-- Phần nhận diện khuôn mặt - ArcFace -->
    <section class="report-section" id="arcface">
        <h2 class="section-title">Nhận diện khuôn mặt với ArcFace</h2>

        <p>
            Sau khi phát hiện khuôn mặt, bước tiếp theo trong hệ thống nhận diện khuôn mặt là nhận dạng danh tính của khuôn mặt đó. Trong phần này, chúng tôi sẽ tập trung vào ArcFace - một trong những mô hình nhận diện khuôn mặt hiện đại và hiệu quả nhất hiện nay.
        </p>

        <h3 class="subsection-title">1. Kiến trúc và nguyên lý hoạt động của ArcFace</h3>

        <p>
            ArcFace (Additive Angular Margin Loss for Deep Face Recognition) là một phương pháp nhận diện khuôn mặt dựa trên mạng nơ-ron tích chập sâu (CNN) với một hàm mất mát đặc biệt được thiết kế để tối ưu hóa khả năng phân biệt giữa các khuôn mặt khác nhau.
        </p>

        <h4 class="subsection-title">1.1 Kiến trúc mạng</h4>

        <p>
            Kiến trúc mạng của ArcFace thường bao gồm:
        </p>

        <ul>
            <li><strong>Backbone Network:</strong> Thường sử dụng ResNet hoặc MobileNet để trích xuất đặc trưng từ ảnh đầu vào.</li>
            <li><strong>Feature Layer:</strong> Một lớp fully-connected để chuyển đổi đặc trưng thành vector nhúng (embedding vector) có kích thước cố định (thường là 512 chiều).</li>
            <li><strong>L2-Normalization:</strong> Chuẩn hóa vector nhúng để có độ dài bằng 1, giúp tính toán góc giữa các vector dễ dàng hơn.</li>
            <li><strong>Fully-connected Layer:</strong> Lớp cuối cùng để phân loại, với số nơ-ron bằng số lượng danh tính cần nhận diện.</li>
        </ul>

        <div class="report-note">
            <p>
                Điểm đặc biệt của ArcFace không nằm ở kiến trúc mạng mà ở hàm mất mát (loss function) được sử dụng để huấn luyện mô hình.
            </p>
        </div>

        <h4 class="subsection-title">1.2 Additive Angular Margin Loss</h4>

        <p>
            Hàm mất mát truyền thống trong các bài toán phân loại là Softmax Loss:
        </p>

        <div class="report-formula">
            $$L_{softmax} = -\frac{1}{N} \sum_{i=1}^{N} \log \frac{e^{W_{y_i}^T x_i + b_{y_i}}}{\sum_{j=1}^{n} e^{W_j^T x_i + b_j}}$$
        </div>

        <p>
            Trong đó:
        </p>
        <ul>
            <li>$x_i$ là vector đặc trưng của mẫu thứ i</li>
            <li>$W_j$ là vector trọng số của lớp j</li>
            <li>$b_j$ là bias của lớp j</li>
            <li>$y_i$ là nhãn thực của mẫu thứ i</li>
        </ul>

        <p>
            Tuy nhiên, Softmax Loss không tối ưu hóa trực tiếp khoảng cách giữa các lớp, dẫn đến khả năng phân biệt không cao. ArcFace giải quyết vấn đề này bằng cách thêm một biên góc (angular margin) vào góc giữa vector đặc trưng và vector trọng số:
        </p>

        <div class="report-formula">
            $$L_{ArcFace} = -\frac{1}{N} \sum_{i=1}^{N} \log \frac{e^{s \cdot \cos(\theta_{y_i} + m)}}{e^{s \cdot \cos(\theta_{y_i} + m)} + \sum_{j=1, j \neq y_i}^{n} e^{s \cdot \cos\theta_j}}$$
        </div>

        <p>
            Trong đó:
        </p>
        <ul>
            <li>$\theta_j$ là góc giữa vector đặc trưng $x_i$ và vector trọng số $W_j$</li>
            <li>$m$ là biên góc (thường là 0.5 radian)</li>
            <li>$s$ là hệ số tỷ lệ (thường là 64)</li>
        </ul>

        <div class="feature-item">
            <h5>Ý nghĩa của Additive Angular Margin:</h5>
            <p>
                Bằng cách thêm biên góc $m$ vào góc $\theta_{y_i}$ (góc giữa vector đặc trưng và vector trọng số của lớp đúng), ArcFace buộc mô hình phải học cách tạo ra các vector đặc trưng có góc nhỏ hơn với vector trọng số của lớp đúng. Điều này dẫn đến:
            </p>
            <ul>
                <li><strong>Intra-class compactness:</strong> Các vector đặc trưng của cùng một người sẽ gần nhau hơn trong không gian đặc trưng.</li>
                <li><strong>Inter-class discrepancy:</strong> Các vector đặc trưng của những người khác nhau sẽ xa nhau hơn.</li>
            </ul>
        </div>

        <h3 class="subsection-title">2. Đánh giá hiệu suất của ArcFace</h3>

        <p>
            Để đánh giá hiệu suất của ArcFace trong nhận diện khuôn mặt, chúng tôi sử dụng các chỉ số đánh giá sau:
        </p>

        <div class="row">
            <div class="col-md-6">
                <div class="feature-item">
                    <h5>Accuracy và F1 Score</h5>
                    <p>
                        Đo lường độ chính xác tổng thể của mô hình trong việc xác định xem hai khuôn mặt có thuộc về cùng một người hay không.
                    </p>
                    <ul>
                        <li><strong>Accuracy:</strong> Tỷ lệ dự đoán đúng trên tổng số mẫu.</li>
                        <li><strong>F1 Score:</strong> Trung bình điều hòa của Precision và Recall, phản ánh sự cân bằng giữa hai chỉ số này.</li>
                    </ul>
                </div>
            </div>
            <div class="col-md-6">
                <div class="feature-item">
                    <h5>FAR, FRR và ERR</h5>
                    <p>
                        Các chỉ số đánh giá quan trọng trong hệ thống sinh trắc học:
                    </p>
                    <ul>
                        <li><strong>FAR (False Acceptance Rate):</strong> Tỷ lệ chấp nhận sai - hệ thống nhận diện sai người lạ là người quen.</li>
                        <li><strong>FRR (False Rejection Rate):</strong> Tỷ lệ từ chối sai - hệ thống không nhận ra người quen.</li>
                        <li><strong>ERR (Equal Error Rate):</strong> Tỷ lệ lỗi khi FAR = FRR, là một chỉ số quan trọng để đánh giá tổng thể hiệu suất của hệ thống.</li>
                    </ul>
                </div>
            </div>
        </div>

        <h4 class="subsection-title">2.1 So sánh hiệu suất giữa các mô hình nhúng đặc trưng</h4>

        <p>
            Chúng tôi so sánh hiệu suất của ArcFace với hai mô hình nhúng đặc trưng phổ biến khác là FaceNet và EfficientNet:
        </p>

        <div class="table-responsive">
            <table class="table feature-table">
                <thead>
                    <tr>
                        <th>Mô hình</th>
                        <th>Accuracy</th>
                        <th>F1 Score</th>
                        <th>FAR</th>
                        <th>FRR</th>
                        <th>ERR</th>
                        <th>AUC</th>
                        <th>Thời gian xử lý (ms)</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>ArcFace</td>
                        <td>0.95</td>
                        <td>0.94</td>
                        <td>0.06</td>
                        <td>0.05</td>
                        <td>0.055</td>
                        <td>0.98</td>
                        <td>85</td>
                    </tr>
                    <tr>
                        <td>FaceNet</td>
                        <td>0.92</td>
                        <td>0.91</td>
                        <td>0.09</td>
                        <td>0.08</td>
                        <td>0.085</td>
                        <td>0.96</td>
                        <td>95</td>
                    </tr>
                    <tr>
                        <td>EfficientNet</td>
                        <td>0.90</td>
                        <td>0.89</td>
                        <td>0.12</td>
                        <td>0.10</td>
                        <td>0.11</td>
                        <td>0.94</td>
                        <td>65</td>
                    </tr>
                </tbody>
            </table>
        </div>

        <h4 class="subsection-title">2.2 Phân tích kết quả</h4>

        <p>
            Từ kết quả so sánh trên, chúng ta có thể rút ra một số nhận xét quan trọng:
        </p>

        <ul>
            <li><strong>ArcFace</strong> đạt hiệu suất cao nhất về độ chính xác (Accuracy = 0.95, F1 Score = 0.94) và có tỷ lệ lỗi thấp nhất (ERR = 0.055). Mô hình này cũng có diện tích dưới đường cong ROC (AUC) cao nhất (0.98), thể hiện khả năng phân biệt tốt giữa các cặp khuôn mặt cùng người và khác người.</li>
            <li><strong>FaceNet</strong> có hiệu suất tốt thứ hai, nhưng thời gian xử lý lâu hơn so với cả ArcFace và EfficientNet.</li>
            <li><strong>EfficientNet</strong> có thời gian xử lý nhanh nhất nhưng hiệu suất thấp nhất trong ba mô hình.</li>
        </ul>

        <p>
            ArcFace vượt trội hơn so với các mô hình khác nhờ vào hàm mất mát Additive Angular Margin, giúp tạo ra không gian đặc trưng có tính phân biệt cao. Điều này đặc biệt quan trọng trong các ứng dụng yêu cầu độ chính xác cao như hệ thống an ninh, xác thực sinh trắc học, và kiểm soát truy cập.
        </p>
    </section>

    <!-- Phần kết luận -->
    <section class="report-section" id="conclusion">
        <h2 class="section-title">Kết luận</h2>

        <p>
            Trong báo cáo này, chúng tôi đã trình bày chi tiết về hai thành phần quan trọng của hệ thống nhận diện khuôn mặt: phát hiện khuôn mặt với RetinaFace và nhận dạng khuôn mặt với ArcFace.
        </p>

        <h3 class="subsection-title">Tổng kết về phát hiện khuôn mặt</h3>

        <p>
            RetinaFace là một mô hình phát hiện khuôn mặt tiên tiến với kiến trúc đa nhiệm vụ, có khả năng không chỉ xác định vị trí khuôn mặt mà còn dự đoán các điểm mốc khuôn mặt và thông tin 3D. So với các mô hình khác như MTCNN, Haar Cascade và YOLO, RetinaFace đạt được độ chính xác cao nhất (IoU = 0.89) nhưng cũng đòi hỏi thời gian xử lý lâu hơn.
        </p>

        <p>
            Việc lựa chọn mô hình phát hiện khuôn mặt phù hợp phụ thuộc vào yêu cầu cụ thể của ứng dụng:
        </p>

        <ul>
            <li>Nếu ưu tiên độ chính xác cao, RetinaFace là lựa chọn tốt nhất.</li>
            <li>Nếu cần cân bằng giữa độ chính xác và tốc độ, MTCNN là một lựa chọn hợp lý.</li>
            <li>Nếu ưu tiên tốc độ xử lý trong thời gian thực, YOLO hoặc Haar Cascade có thể là lựa chọn phù hợp hơn.</li>
        </ul>

        <h3 class="subsection-title">Tổng kết về nhận dạng khuôn mặt</h3>

        <p>
            ArcFace là một phương pháp nhận dạng khuôn mặt hiệu quả với hàm mất mát Additive Angular Margin đặc biệt, giúp tạo ra không gian đặc trưng có tính phân biệt cao. So với các mô hình khác như FaceNet và EfficientNet, ArcFace đạt được hiệu suất cao nhất về độ chính xác (Accuracy = 0.95) và có tỷ lệ lỗi thấp nhất (ERR = 0.055).
        </p>

        <p>
            Việc kết hợp RetinaFace cho phát hiện khuôn mặt và ArcFace cho nhận dạng khuôn mặt tạo nên một hệ thống nhận diện khuôn mặt mạnh mẽ và chính xác, phù hợp cho nhiều ứng dụng thực tế như:
        </p>

        <ul>
            <li>Hệ thống an ninh và giám sát</li>
            <li>Kiểm soát truy cập và xác thực sinh trắc học</li>
            <li>Tìm kiếm và nhận dạng người trong cơ sở dữ liệu lớn</li>
            <li>Ứng dụng tương tác người-máy thông minh</li>
        </ul>

        <h3 class="subsection-title">Hướng phát triển trong tương lai</h3>

        <p>
            Mặc dù đã đạt được những tiến bộ đáng kể, lĩnh vực nhận diện khuôn mặt vẫn còn nhiều thách thức và hướng phát triển trong tương lai:
        </p>

        <ul>
            <li><strong>Cải thiện khả năng chống giả mạo:</strong> Phát triển các phương pháp phát hiện khuôn mặt giả (anti-spoofing) để tăng cường an ninh cho hệ thống nhận diện khuôn mặt.</li>
            <li><strong>Nhận diện trong điều kiện khó khăn:</strong> Cải thiện hiệu suất nhận diện trong điều kiện ánh sáng kém, góc nghiêng lớn, hoặc khuôn mặt bị che khuất một phần.</li>
            <li><strong>Giảm thiểu sự thiên vị:</strong> Phát triển các mô hình công bằng hơn, giảm thiểu sự thiên vị đối với các nhóm dân số khác nhau.</li>
            <li><strong>Bảo vệ quyền riêng tư:</strong> Nghiên cứu các phương pháp nhận diện khuôn mặt bảo vệ quyền riêng tư, như học liên hợp (federated learning) hoặc mã hóa đồng hình (homomorphic encryption).</li>
        </ul>

        <p>
            Với sự phát triển không ngừng của các kỹ thuật học sâu và tăng cường dữ liệu, chúng ta có thể kỳ vọng vào những tiến bộ đáng kể trong lĩnh vực nhận diện khuôn mặt trong tương lai, mở ra nhiều ứng dụng mới và cải thiện các ứng dụng hiện có.
        </p>
    </section>

    <!-- Phần tham khảo -->
    <section class="reference">
        <h3>Tài liệu tham khảo</h3>
        <ol>
            <li>Deng, J., Guo, J., Zhou, Y., Yu, J., Kotsia, I., & Zafeiriou, S. (2019). RetinaFace: Single-stage Dense Face Localisation in the Wild. arXiv preprint arXiv:1905.00641.</li>
            <li>Deng, J., Guo, J., Xue, N., & Zafeiriou, S. (2019). ArcFace: Additive Angular Margin Loss for Deep Face Recognition. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 4690-4699).</li>
            <li>Zhang, K., Zhang, Z., Li, Z., & Qiao, Y. (2016). Joint face detection and alignment using multitask cascaded convolutional networks. IEEE Signal Processing Letters, 23(10), 1499-1503.</li>
            <li>Viola, P., & Jones, M. (2001). Rapid object detection using a boosted cascade of simple features. In Proceedings of the 2001 IEEE computer society conference on computer vision and pattern recognition.</li>
            <li>Redmon, J., & Farhadi, A. (2018). YOLOv3: An incremental improvement. arXiv preprint arXiv:1804.02767.</li>
            <li>Schroff, F., Kalenichenko, D., & Philbin, J. (2015). FaceNet: A unified embedding for face recognition and clustering. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 815-823).</li>
            <li>Tan, M., & Le, Q. (2019). EfficientNet: Rethinking model scaling for convolutional neural networks. In International Conference on Machine Learning (pp. 6105-6114).</li>
        </ol>
    </section>
</div>
{% endblock %}
