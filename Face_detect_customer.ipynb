{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMNwNpF3+TB8KdCSU40CQ7a"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Bo-Izsawvwpj","executionInfo":{"status":"ok","timestamp":1745376710177,"user_tz":-420,"elapsed":23859,"user":{"displayName":"Huệ Trần Thị Thanh","userId":"01694173941333005562"}},"outputId":"fe005974-0654-49e1-d0e5-a02541a4f967"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["pip install mtcnn"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0ymrh_i8xRcA","executionInfo":{"status":"ok","timestamp":1745304717735,"user_tz":-420,"elapsed":3422,"user":{"displayName":"Huệ Trần Thị Thanh","userId":"01694173941333005562"}},"outputId":"875c0c39-82d0-4c5c-fe75-9ba1ccbdff11"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting mtcnn\n","  Downloading mtcnn-1.0.0-py3-none-any.whl.metadata (5.8 kB)\n","Requirement already satisfied: joblib>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from mtcnn) (1.4.2)\n","Collecting lz4>=4.3.3 (from mtcnn)\n","  Downloading lz4-4.4.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n","Downloading mtcnn-1.0.0-py3-none-any.whl (1.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading lz4-4.4.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: lz4, mtcnn\n","Successfully installed lz4-4.4.4 mtcnn-1.0.0\n"]}]},{"cell_type":"code","source":["import os\n","import time\n","import cv2\n","import numpy as np\n","import pandas as pd\n","import xml.etree.ElementTree as ET\n","from mtcnn import MTCNN\n","from PIL import Image\n","\n","# Khởi tạo detector\n","detector = MTCNN()\n","\n","# Load ground truth\n","def load_annotations(xml_file):\n","    tree = ET.parse(xml_file)\n","    root = tree.getroot()\n","    data = {}\n","    for image in root.findall(\"image\"):\n","        file_name = image.attrib[\"name\"]\n","        box = image.find(\"box\")\n","        x1, y1 = float(box.attrib[\"xtl\"]), float(box.attrib[\"ytl\"])\n","        x2, y2 = float(box.attrib[\"xbr\"]), float(box.attrib[\"ybr\"])\n","        data[file_name] = (x1, y1, x2, y2)\n","    return data\n","\n","# Tính IoU\n","def compute_iou(boxA, boxB):\n","    xA = max(boxA[0], boxB[0])\n","    yA = max(boxA[1], boxB[1])\n","    xB = min(boxA[2], boxB[2])\n","    yB = min(boxA[3], boxB[3])\n","\n","    interArea = max(0, xB - xA) * max(0, yB - yA)\n","    if interArea == 0:\n","        return 0.0\n","    boxAArea = max(1e-6, (boxA[2] - boxA[0]) * (boxA[3] - boxA[1]))\n","    boxBArea = max(1e-6, (boxB[2] - boxB[0]) * (boxB[3] - boxB[1]))\n","    return interArea / (boxAArea + boxBArea - interArea)\n","\n","# Khoảng cách giữa hai tâm\n","def compute_center_distance(box1, box2):\n","    cx1 = (box1[0] + box1[2]) / 2\n","    cy1 = (box1[1] + box1[3]) / 2\n","    cx2 = (box2[0] + box2[2]) / 2\n","    cy2 = (box2[1] + box2[3]) / 2\n","    return np.sqrt((cx1 - cx2)**2 + (cy1 - cy2)**2)\n","\n","# Xử lý toàn bộ ảnh\n","def process_images(base_folder, annotation_path):\n","    annotations = load_annotations(annotation_path)\n","    records = []\n","\n","    for root, _, files in os.walk(base_folder):\n","        for file in files:\n","            if not file.lower().endswith((\".jpg\", \".png\", \".jpeg\")):\n","                continue\n","            file_path = os.path.join(root, file)\n","            rel_path = os.path.relpath(file_path, base_folder).replace(\"\\\\\", \"/\")\n","            image_key = f\"image_customer/{rel_path}\"\n","\n","            img = cv2.imread(file_path)\n","            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","\n","            start = time.time()\n","            results = detector.detect_faces(img_rgb)\n","            inference_time = time.time() - start\n","\n","            pred_box = [0, 0, 0, 0]\n","\n","            # Chỉ lấy face có độ tin cậy cao nhất\n","            if results:\n","                best_result = max(results, key=lambda x: x['confidence'])\n","                x, y, w, h = best_result['box']\n","                pred_box = [x, y, x + w, y + h]\n","\n","            gt_box = annotations.get(image_key, [0, 0, 0, 0])\n","            iou = compute_iou(pred_box, gt_box)\n","            center_distance = compute_center_distance(pred_box, gt_box)\n","\n","            records.append({\n","                \"file_name\": image_key,\n","                \"x1\": pred_box[0],\n","                \"y1\": pred_box[1],\n","                \"x2\": pred_box[2],\n","                \"y2\": pred_box[3],\n","                \"IoU\": iou,\n","                \"center_distance\": center_distance,\n","                \"inference_time\": inference_time\n","            })\n","\n","    return pd.DataFrame(records)\n","\n"],"metadata":{"id":"JMVabVjLxChc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["annotation_path = \"/content/drive/MyDrive/Report/data/annotations.xml\"\n","image_folder = \"/content/drive/MyDrive/Report/data/image_customer\"\n","\n","df = process_images(image_folder, annotation_path)\n","df.to_csv(\"/content/drive/MyDrive/Report/result/MTCNN_face_detection.csv\", index=False)\n","print(\"✅ Đã hoàn tất và lưu kết quả!\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":321},"id":"kRmQDdjYxcey","executionInfo":{"status":"error","timestamp":1745312158237,"user_tz":-420,"elapsed":64,"user":{"displayName":"Huệ Trần Thị Thanh","userId":"01694173941333005562"}},"outputId":"7482a26d-f098-4ba6-98f3-8ac146dca5c1"},"execution_count":null,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/path/to/annotations.xml'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-00f5dbcac82e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0moutput_csv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/path/to/output/results.csv\"\u001b[0m  \u001b[0;31m# Đường dẫn tới file CSV để lưu kết quả\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mevaluate_face_detection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdet_model_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannotation_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_csv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-21-14e960feb298>\u001b[0m in \u001b[0;36mevaluate_face_detection\u001b[0;34m(image_folder, det_model_path, annotation_file, output_csv)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mevaluate_face_detection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdet_model_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannotation_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_csv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;34m\"\"\"Đánh giá phát hiện khuôn mặt với RetinaFace và lưu kết quả vào CSV\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m     \u001b[0mresults_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdet_model_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannotation_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m     \u001b[0mresults_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_csv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-21-14e960feb298>\u001b[0m in \u001b[0;36mprocess_images\u001b[0;34m(image_folder, det_model_path, annotation_file)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprocess_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdet_model_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannotation_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0mannotations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_annotations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mannotation_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m     \u001b[0mrecords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-21-14e960feb298>\u001b[0m in \u001b[0;36mload_annotations\u001b[0;34m(xml_file)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_annotations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxml_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;34m\"\"\"Tải dữ liệu ground truth từ file XML\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mET\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxml_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetroot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/xml/etree/ElementTree.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(source, parser)\u001b[0m\n\u001b[1;32m   1217\u001b[0m     \"\"\"\n\u001b[1;32m   1218\u001b[0m     \u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mElementTree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m     \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/xml/etree/ElementTree.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, source, parser)\u001b[0m\n\u001b[1;32m    568\u001b[0m         \u001b[0mclose_source\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"read\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m             \u001b[0msource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m             \u001b[0mclose_source\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/path/to/annotations.xml'"]}]},{"cell_type":"markdown","source":["# Haar"],"metadata":{"id":"yhjSLOn1P8Ev"}},{"cell_type":"code","source":["import os\n","import cv2\n","import time\n","import pandas as pd\n","import xml.etree.ElementTree as ET\n","from math import sqrt\n","\n","# Load Haar Cascade\n","face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n","\n","# Load Ground Truth từ XML\n","def load_annotations(xml_file):\n","    tree = ET.parse(xml_file)\n","    root = tree.getroot()\n","    data = {}\n","    for image in root.findall(\"image\"):\n","        file_name = image.attrib[\"name\"]\n","        box = image.find(\"box\")\n","        if box is not None:\n","            x1 = float(box.attrib[\"xtl\"])\n","            y1 = float(box.attrib[\"ytl\"])\n","            x2 = float(box.attrib[\"xbr\"])\n","            y2 = float(box.attrib[\"ybr\"])\n","            data[file_name] = (x1, y1, x2, y2)  # ✅ đúng định dạng (x1, y1, x2, y2)\n","    return data\n","\n","# Tính IoU theo định dạng (x1, y1, x2, y2)\n","def calculate_iou(boxA, boxB):\n","    xA = max(boxA[0], boxB[0])\n","    yA = max(boxA[1], boxB[1])\n","    xB = min(boxA[2], boxB[2])\n","    yB = min(boxA[3], boxB[3])\n","\n","    interArea = max(0, xB - xA) * max(0, yB - yA)\n","    if interArea == 0:\n","        return 0.0\n","\n","    boxAArea = (boxA[2] - boxA[0]) * (boxA[3] - boxA[1])\n","    boxBArea = (boxB[2] - boxB[0]) * (boxB[3] - boxB[1])\n","    iou = interArea / float(boxAArea + boxBArea - interArea + 1e-6)\n","    return iou\n","\n","# Tính khoảng cách tâm box theo định dạng (x1, y1, x2, y2)\n","def calculate_center_distance(box1, box2):\n","    cx1 = (box1[0] + box1[2]) / 2\n","    cy1 = (box1[1] + box1[3]) / 2\n","    cx2 = (box2[0] + box2[2]) / 2\n","    cy2 = (box2[1] + box2[3]) / 2\n","    return sqrt((cx1 - cx2)**2 + (cy1 - cy2)**2)\n","\n","# Đường dẫn\n","image_root = \"/content/drive/MyDrive/Report/data/image_customer\"\n","annotation_file = '/content/drive/MyDrive/Report/data/annotations.xml'\n","output_csv = '/content/drive/MyDrive/Report/result/Haar_face_detection.csv'\n","\n","# Load ground truth\n","groundtruth = load_annotations(annotation_file)\n","\n","results = []\n","\n","for dirpath, _, filenames in os.walk(image_root):\n","    for fname in filenames:\n","        if fname.lower().endswith(('.jpg', '.png')):\n","            full_path = os.path.join(dirpath, fname)\n","            rel_path = os.path.relpath(full_path, image_root).replace(\"\\\\\", \"/\")\n","            image_key = f\"image_customer/{rel_path}\"  # ✅ giống với key trong XML\n","\n","            img = cv2.imread(full_path)\n","            if img is None:\n","                print(f\"[ERROR] Không thể đọc ảnh: {full_path}\")\n","                continue\n","\n","            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","\n","            start_time = time.time()\n","            faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)\n","            inference_time = time.time() - start_time\n","\n","            # Chọn face lớn nhất nếu có\n","            if len(faces) > 0:\n","                x, y, w, h = max(faces, key=lambda b: b[2]*b[3])\n","                pred_box = (x, y, x + w, y + h)\n","            else:\n","                pred_box = (0, 0, 0, 0)\n","\n","            gt_box = groundtruth.get(image_key, (0, 0, 0, 0))\n","            iou = calculate_iou(gt_box, pred_box)\n","            dist = calculate_center_distance(gt_box, pred_box)\n","\n","            results.append({\n","                'filename': image_key,\n","                'x1': pred_box[0],\n","                'y1': pred_box[1],\n","                'x2': pred_box[2],\n","                'y2': pred_box[3],\n","                'IoU': round(iou, 4),\n","                'center_distance': round(dist, 2),\n","                'inference_time': round(inference_time, 4)\n","            })\n","\n","# Xuất ra CSV\n","df = pd.DataFrame(results)\n","df.to_csv(output_csv, index=False)\n","print(f\"[INFO] Đã lưu kết quả vào: {output_csv}\")\n"],"metadata":{"id":"maay1J7HP7FU","executionInfo":{"status":"ok","timestamp":1745379763220,"user_tz":-420,"elapsed":139590,"user":{"displayName":"Huệ Trần Thị Thanh","userId":"01694173941333005562"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"2d1a0d1d-b02f-4c79-ea87-d6c5ab1f5777"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["[INFO] Đã lưu kết quả vào: /content/drive/MyDrive/Report/result/Haar_face_detection.csv\n"]}]},{"cell_type":"markdown","source":["# Yolo"],"metadata":{"id":"_AxocDcPXbpU"}},{"cell_type":"code","source":["pip install ultralytics"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y51XK74KXubQ","executionInfo":{"status":"ok","timestamp":1745376999152,"user_tz":-420,"elapsed":130680,"user":{"displayName":"Huệ Trần Thị Thanh","userId":"01694173941333005562"}},"outputId":"d8ddce63-eb5a-458c-e096-a0cc5f77e91f"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting ultralytics\n","  Downloading ultralytics-8.3.114-py3-none-any.whl.metadata (37 kB)\n","Requirement already satisfied: numpy<=2.1.1,>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.2)\n","Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n","Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\n","Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.1.0)\n","Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.14.1)\n","Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n","Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n","Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n","Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n","Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.13.2)\n","Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n","  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.57.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.13.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n","Downloading ultralytics-8.3.114-py3-none-any.whl (983 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.5/983.5 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m989.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m86.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n","Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ultralytics-8.3.114 ultralytics-thop-2.0.14\n"]}]},{"cell_type":"code","source":["import os\n","import cv2\n","import time\n","import torch\n","import numpy as np\n","import pandas as pd\n","import xml.etree.ElementTree as ET\n","from ultralytics import YOLO\n","import logging\n","from tqdm import tqdm\n","\n","logging.getLogger(\"ultralytics\").setLevel(logging.WARNING)\n","\n","# ===================== PHẦN 1: HÀM TÍNH TOÁN =====================\n","\n","def calculate_iou(boxA, boxB):\n","    \"\"\"Tính IoU giữa hai bounding box định dạng (x1, y1, x2, y2)\"\"\"\n","    xA = max(boxA[0], boxB[0])\n","    yA = max(boxA[1], boxB[1])\n","    xB = min(boxA[2], boxB[2])\n","    yB = min(boxA[3], boxB[3])\n","\n","    interArea = max(0, xB - xA) * max(0, yB - yA)\n","    if interArea == 0:\n","        return 0.0\n","\n","    boxAArea = (boxA[2] - boxA[0]) * (boxA[3] - boxA[1])\n","    boxBArea = (boxB[2] - boxB[0]) * (boxB[3] - boxB[1])\n","    return interArea / float(boxAArea + boxBArea - interArea + 1e-6)\n","\n","def calculate_center_distance(box1, box2):\n","    \"\"\"Tính khoảng cách giữa hai tâm bounding box định dạng (x1, y1, x2, y2)\"\"\"\n","    cx1 = (box1[0] + box1[2]) / 2\n","    cy1 = (box1[1] + box1[3]) / 2\n","    cx2 = (box2[0] + box2[2]) / 2\n","    cy2 = (box2[1] + box2[3]) / 2\n","    return np.sqrt((cx1 - cx2)**2 + (cy1 - cy2)**2)\n","\n","# ===================== PHẦN 2: PHÁT HIỆN KHUÔN MẶT =====================\n","\n","class YOLOFaceDetector:\n","    def __init__(self, model_path, device='cuda' if torch.cuda.is_available() else 'cpu'):\n","        self.device = device\n","        self.model = YOLO(model_path).to(device)\n","\n","    def detect(self, img_path, conf_thres=0.25, iou_thres=0.45):\n","        img = cv2.imread(img_path)\n","        if img is None:\n","            print(f\"[ERROR] Không thể đọc ảnh: {img_path}\")\n","            return []\n","\n","        results = self.model.predict(img, conf=conf_thres, iou=iou_thres, device=self.device)\n","        best_box = None\n","        best_conf = -1\n","\n","        for result in results:\n","            for box, conf in zip(result.boxes.xyxy.cpu().numpy(), result.boxes.conf.cpu().numpy()):\n","                if conf > best_conf:\n","                    x1, y1, x2, y2 = map(int, box[:4])\n","                    best_box = (x1, y1, x2, y2)  # ✅ giữ nguyên (x1, y1, x2, y2)\n","                    best_conf = conf\n","\n","        if best_box is None:\n","            print(f\"[WARNING] Không phát hiện khuôn mặt trong ảnh: {img_path}\")\n","        return [best_box] if best_box else []\n","\n","# ===================== PHẦN 3: LOAD GROUND TRUTH =====================\n","\n","def load_annotations(xml_file):\n","    tree = ET.parse(xml_file)\n","    root = tree.getroot()\n","    data = {}\n","    for image in root.findall(\"image\"):\n","        file_name = image.attrib[\"name\"]  # đã bao gồm image_customer/\n","        box = image.find(\"box\")\n","        if box is not None:\n","            x1 = float(box.attrib[\"xtl\"])\n","            y1 = float(box.attrib[\"ytl\"])\n","            x2 = float(box.attrib[\"xbr\"])\n","            y2 = float(box.attrib[\"ybr\"])\n","            data[file_name] = (x1, y1, x2, y2)  # ✅ giữ nguyên (x1, y1, x2, y2)\n","    return data\n","\n","# ===================== PHẦN 4: ĐÁNH GIÁ TOÀN BỘ =====================\n","\n","def evaluate_yolo_face(image_root, model_path, annotation_path, output_csv):\n","    detector = YOLOFaceDetector(model_path)\n","    annotations = load_annotations(annotation_path)\n","    results = []\n","\n","    for dirpath, _, filenames in os.walk(image_root):\n","        for fname in tqdm(filenames, desc=\"Processing\"):\n","            if not fname.lower().endswith(('.jpg', '.png', '.jpeg')):\n","                continue\n","\n","            full_path = os.path.join(dirpath, fname)\n","            rel_path = os.path.relpath(full_path, image_root).replace(\"\\\\\", \"/\")\n","            image_key = f\"image_customer/{rel_path}\"\n","\n","            start = time.time()\n","            detections = detector.detect(full_path)\n","            duration = time.time() - start\n","\n","            if detections:\n","                pred_box = detections[0]  # (x1, y1, x2, y2)\n","            else:\n","                pred_box = (0, 0, 0, 0)\n","\n","            gt_box = annotations.get(image_key, (0, 0, 0, 0))\n","            iou = calculate_iou(pred_box, gt_box)\n","            dist = calculate_center_distance(pred_box, gt_box)\n","\n","            results.append({\n","                'file_name': image_key,\n","                'x1': pred_box[0],\n","                'y1': pred_box[1],\n","                'x2': pred_box[2],\n","                'y2': pred_box[3],\n","                'IoU': round(iou, 4),\n","                'center_distance': round(dist, 2),\n","                'inference_time': round(duration, 4)\n","            })\n","\n","    df = pd.DataFrame(results)\n","    df.to_csv(output_csv, index=False)\n","    print(f\"[INFO] Kết quả đã được lưu tại: {output_csv}\")\n","\n","# ===================== PHẦN 5: CHẠY =====================\n","\n","if __name__ == \"__main__\":\n","    image_root = '/content/drive/MyDrive/Report/data/image_customer'\n","    model_path = '/content/drive/MyDrive/Report/model/best.pt'\n","    annotation_path = '/content/drive/MyDrive/Report/data/annotations.xml'\n","    output_csv = '/content/drive/MyDrive/Report/result/Yolo_face_detection.csv'\n","\n","    evaluate_yolo_face(image_root, model_path, annotation_path, output_csv)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jfTgNx2SXc1j","executionInfo":{"status":"ok","timestamp":1745380158777,"user_tz":-420,"elapsed":53903,"user":{"displayName":"Huệ Trần Thị Thanh","userId":"01694173941333005562"}},"outputId":"2ce79523-49da-4be5-da5a-ff89c31e3d34"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stderr","text":["Processing: 0it [00:00, ?it/s]\n","Processing: 100%|██████████| 4/4 [00:00<00:00,  5.60it/s]\n","Processing: 100%|██████████| 4/4 [00:01<00:00,  3.97it/s]\n","Processing: 100%|██████████| 4/4 [00:01<00:00,  3.89it/s]\n","Processing: 100%|██████████| 4/4 [00:01<00:00,  4.00it/s]\n","Processing: 100%|██████████| 4/4 [00:00<00:00,  4.88it/s]\n","Processing: 100%|██████████| 4/4 [00:00<00:00,  5.76it/s]\n","Processing: 100%|██████████| 4/4 [00:00<00:00,  6.00it/s]\n","Processing: 100%|██████████| 4/4 [00:00<00:00,  6.97it/s]\n","Processing: 100%|██████████| 4/4 [00:00<00:00,  6.63it/s]\n","Processing: 100%|██████████| 4/4 [00:00<00:00,  6.62it/s]\n","Processing: 100%|██████████| 4/4 [00:00<00:00,  7.28it/s]\n","Processing: 100%|██████████| 4/4 [00:00<00:00,  6.42it/s]\n","Processing: 100%|██████████| 4/4 [00:00<00:00,  5.89it/s]\n","Processing: 100%|██████████| 4/4 [00:00<00:00,  6.73it/s]\n","Processing: 100%|██████████| 4/4 [00:00<00:00,  7.27it/s]\n","Processing: 100%|██████████| 4/4 [00:00<00:00,  7.12it/s]\n","Processing: 100%|██████████| 4/4 [00:00<00:00,  5.70it/s]\n","Processing: 100%|██████████| 4/4 [00:00<00:00,  5.38it/s]\n","Processing: 100%|██████████| 4/4 [00:00<00:00,  6.17it/s]\n","Processing: 100%|██████████| 4/4 [00:00<00:00,  7.01it/s]\n","Processing: 100%|██████████| 4/4 [00:00<00:00,  5.13it/s]\n","Processing: 100%|██████████| 4/4 [00:00<00:00,  4.16it/s]\n","Processing: 100%|██████████| 4/4 [00:00<00:00,  4.13it/s]\n","Processing: 100%|██████████| 4/4 [00:01<00:00,  3.91it/s]\n","Processing: 100%|██████████| 4/4 [00:00<00:00,  5.59it/s]\n","Processing: 100%|██████████| 4/4 [00:00<00:00,  4.12it/s]\n","Processing: 100%|██████████| 4/4 [00:00<00:00,  5.79it/s]\n","Processing: 100%|██████████| 4/4 [00:00<00:00,  6.51it/s]\n","Processing: 100%|██████████| 4/4 [00:00<00:00,  6.42it/s]\n","Processing: 100%|██████████| 4/4 [00:00<00:00,  6.23it/s]\n","Processing: 100%|██████████| 4/4 [00:00<00:00,  6.42it/s]\n","Processing: 100%|██████████| 4/4 [00:00<00:00,  6.51it/s]\n","Processing: 100%|██████████| 4/4 [00:00<00:00,  5.42it/s]\n","Processing: 100%|██████████| 4/4 [00:00<00:00,  6.07it/s]\n","Processing: 100%|██████████| 4/4 [00:01<00:00,  3.92it/s]\n","Processing: 100%|██████████| 4/4 [00:00<00:00,  6.18it/s]\n","Processing: 100%|██████████| 4/4 [00:00<00:00,  7.30it/s]\n","Processing: 100%|██████████| 4/4 [00:00<00:00,  6.52it/s]\n","Processing: 100%|██████████| 4/4 [00:00<00:00,  5.33it/s]\n","Processing: 100%|██████████| 4/4 [00:01<00:00,  3.88it/s]\n","Processing: 100%|██████████| 4/4 [00:01<00:00,  3.71it/s]\n","Processing: 100%|██████████| 4/4 [00:00<00:00,  4.41it/s]\n","Processing: 100%|██████████| 4/4 [00:00<00:00,  4.91it/s]\n","Processing: 100%|██████████| 4/4 [00:00<00:00,  4.23it/s]\n","Processing: 100%|██████████| 4/4 [00:00<00:00,  6.69it/s]\n","Processing: 100%|██████████| 4/4 [00:00<00:00,  6.02it/s]\n","Processing: 100%|██████████| 4/4 [00:00<00:00,  6.06it/s]\n","Processing: 100%|██████████| 4/4 [00:00<00:00,  5.65it/s]\n","Processing: 100%|██████████| 4/4 [00:00<00:00,  5.42it/s]\n","Processing: 100%|██████████| 4/4 [00:00<00:00,  7.21it/s]\n","Processing: 100%|██████████| 4/4 [00:00<00:00,  6.62it/s]\n","Processing: 100%|██████████| 4/4 [00:00<00:00,  6.18it/s]\n","Processing: 100%|██████████| 4/4 [00:00<00:00,  6.07it/s]\n","Processing: 100%|██████████| 4/4 [00:00<00:00,  6.96it/s]\n","Processing: 100%|██████████| 4/4 [00:00<00:00,  5.85it/s]\n","Processing: 100%|██████████| 4/4 [00:00<00:00,  5.78it/s]\n","Processing: 100%|██████████| 4/4 [00:00<00:00,  5.35it/s]\n","Processing: 100%|██████████| 4/4 [00:00<00:00,  4.43it/s]\n","Processing: 100%|██████████| 4/4 [00:00<00:00,  4.22it/s]\n","Processing: 100%|██████████| 4/4 [00:01<00:00,  3.08it/s]\n","Processing: 100%|██████████| 4/4 [00:00<00:00,  4.39it/s]\n","Processing: 100%|██████████| 4/4 [00:00<00:00,  5.48it/s]\n","Processing: 100%|██████████| 4/4 [00:00<00:00,  6.02it/s]\n","Processing: 100%|██████████| 4/4 [00:00<00:00,  6.70it/s]\n","Processing: 100%|██████████| 4/4 [00:00<00:00,  6.20it/s]\n","Processing: 100%|██████████| 4/4 [00:00<00:00,  5.19it/s]\n","Processing: 100%|██████████| 4/4 [00:00<00:00,  5.92it/s]\n","Processing: 100%|██████████| 4/4 [00:00<00:00,  5.47it/s]\n","Processing: 100%|██████████| 4/4 [00:00<00:00,  4.67it/s]\n","Processing: 100%|██████████| 4/4 [00:00<00:00,  6.71it/s]\n","Processing: 100%|██████████| 4/4 [00:00<00:00,  5.67it/s]\n","Processing: 100%|██████████| 4/4 [00:00<00:00,  5.46it/s]"]},{"output_type":"stream","name":"stdout","text":["[INFO] Kết quả đã được lưu tại: /content/drive/MyDrive/Report/result/Yolo_face_detection.csv\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"markdown","source":["# Retinaface"],"metadata":{"id":"_-8scM7YgmPU"}},{"cell_type":"code","source":["pip install insightface onnxruntime"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g2n1Ib6kgoLW","executionInfo":{"status":"ok","timestamp":1745377533443,"user_tz":-420,"elapsed":48224,"user":{"displayName":"Huệ Trần Thị Thanh","userId":"01694173941333005562"}},"outputId":"3cb1b72e-260d-4d2a-f516-7aee7530f103"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting insightface\n","  Downloading insightface-0.7.3.tar.gz (439 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/439.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.8/439.5 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.5/439.5 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Collecting onnxruntime\n","  Downloading onnxruntime-1.21.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from insightface) (2.0.2)\n","Collecting onnx (from insightface)\n","  Downloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from insightface) (4.67.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from insightface) (2.32.3)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from insightface) (3.10.0)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from insightface) (11.1.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from insightface) (1.14.1)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from insightface) (1.6.1)\n","Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from insightface) (0.25.2)\n","Requirement already satisfied: easydict in /usr/local/lib/python3.11/dist-packages (from insightface) (1.13)\n","Requirement already satisfied: cython in /usr/local/lib/python3.11/dist-packages (from insightface) (3.0.12)\n","Requirement already satisfied: albumentations in /usr/local/lib/python3.11/dist-packages (from insightface) (2.0.5)\n","Requirement already satisfied: prettytable in /usr/local/lib/python3.11/dist-packages (from insightface) (3.16.0)\n","Collecting coloredlogs (from onnxruntime)\n","  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (25.2.10)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (24.2)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (5.29.4)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (1.13.1)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from albumentations->insightface) (6.0.2)\n","Requirement already satisfied: pydantic>=2.9.2 in /usr/local/lib/python3.11/dist-packages (from albumentations->insightface) (2.11.3)\n","Requirement already satisfied: albucore==0.0.23 in /usr/local/lib/python3.11/dist-packages (from albumentations->insightface) (0.0.23)\n","Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.11/dist-packages (from albumentations->insightface) (4.11.0.86)\n","Requirement already satisfied: stringzilla>=3.10.4 in /usr/local/lib/python3.11/dist-packages (from albucore==0.0.23->albumentations->insightface) (3.12.4)\n","Requirement already satisfied: simsimd>=5.9.2 in /usr/local/lib/python3.11/dist-packages (from albucore==0.0.23->albumentations->insightface) (6.2.1)\n","Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n","  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->insightface) (1.3.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->insightface) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->insightface) (4.57.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->insightface) (1.4.8)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->insightface) (3.2.3)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->insightface) (2.8.2)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prettytable->insightface) (0.2.13)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->insightface) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->insightface) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->insightface) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->insightface) (2025.1.31)\n","Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image->insightface) (3.4.2)\n","Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image->insightface) (2.37.0)\n","Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image->insightface) (2025.3.30)\n","Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->insightface) (0.4)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->insightface) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->insightface) (3.6.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime) (1.3.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations->insightface) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations->insightface) (2.33.1)\n","Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations->insightface) (4.13.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations->insightface) (0.4.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->insightface) (1.17.0)\n","Downloading onnxruntime-1.21.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m66.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m97.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: insightface\n","  Building wheel for insightface (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for insightface: filename=insightface-0.7.3-cp311-cp311-linux_x86_64.whl size=1064780 sha256=abd58ab5ce515bc205bb22877eebe10331b7b5cc647a97beaf21b72d4bbbe1d7\n","  Stored in directory: /root/.cache/pip/wheels/27/d8/22/f52d858d16cd06e7b2e6aad34a1777dcfaf000be833bbf8146\n","Successfully built insightface\n","Installing collected packages: onnx, humanfriendly, coloredlogs, onnxruntime, insightface\n","Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 insightface-0.7.3 onnx-1.17.0 onnxruntime-1.21.1\n"]}]},{"cell_type":"code","source":["import os\n","import cv2\n","import time\n","import numpy as np\n","import pandas as pd\n","import xml.etree.ElementTree as ET\n","from insightface.model_zoo import model_zoo\n","\n","# ===================== PHẦN 1: ĐỌC DỮ LIỆU GROUND TRUTH =====================\n","\n","def load_annotations(xml_file):\n","    \"\"\"Tải dữ liệu ground truth từ file XML\"\"\"\n","    tree = ET.parse(xml_file)\n","    root = tree.getroot()\n","    data = {}\n","    for image in root.findall(\"image\"):\n","        file_name = image.attrib[\"name\"]  # Đã bao gồm 'image_customer/...'\n","        box = image.find(\"box\")\n","        if box is not None:\n","            x1, y1 = float(box.attrib[\"xtl\"]), float(box.attrib[\"ytl\"])\n","            x2, y2 = float(box.attrib[\"xbr\"]), float(box.attrib[\"ybr\"])\n","            data[file_name] = (x1, y1, x2, y2)\n","    return data\n","\n","# ===================== PHẦN 2: TÍNH TOÁN IoU VÀ CENTER DISTANCE =====================\n","\n","def compute_iou(boxA, boxB):\n","    xA = max(boxA[0], boxB[0])\n","    yA = max(boxA[1], boxB[1])\n","    xB = min(boxA[2], boxB[2])\n","    yB = min(boxA[3], boxB[3])\n","\n","    interArea = max(0, xB - xA) * max(0, yB - yA)\n","    if interArea == 0:\n","        return 0.0\n","    boxAArea = max(1e-6, (boxA[2] - boxA[0]) * (boxA[3] - boxA[1]))\n","    boxBArea = max(1e-6, (boxB[2] - boxB[0]) * (boxB[3] - boxB[1]))\n","    return interArea / (boxAArea + boxBArea - interArea)\n","\n","def compute_center_distance(box1, box2):\n","    cx1 = (box1[0] + box1[2]) / 2\n","    cy1 = (box1[1] + box1[3]) / 2\n","    cx2 = (box2[0] + box2[2]) / 2\n","    cy2 = (box2[1] + box2[3]) / 2\n","    return np.sqrt((cx1 - cx2)**2 + (cy1 - cy2)**2)\n","\n","# ===================== PHẦN 3: XỬ LÝ ẢNH VỚI RETINAFACE =====================\n","\n","def process_images(base_folder, det_model_path, annotation_path):\n","    annotations = load_annotations(annotation_path)\n","    records = []\n","\n","    # Khởi tạo RetinaFace detector\n","    det_model = model_zoo.get_model(det_model_path)\n","    det_model.prepare(ctx_id=0, input_size=(640, 640), det_thresh=0.5)\n","\n","    for root, _, files in os.walk(base_folder):\n","        for file in files:\n","            if not file.lower().endswith((\".jpg\", \".png\", \".jpeg\")):\n","                continue\n","\n","            file_path = os.path.join(root, file)\n","            rel_path = os.path.relpath(file_path, base_folder).replace(\"\\\\\", \"/\")\n","            image_key = f\"image_customer/{rel_path}\"  # ✅ KHÔNG thêm \"image_customer/\" vì đã có trong annotation\n","\n","            image = cv2.imread(file_path)\n","            if image is None:\n","                continue\n","\n","            start_time = time.time()\n","            bboxes, _ = det_model.detect(image, max_num=0, metric='default')\n","            inference_time = time.time() - start_time\n","\n","            pred_box = [0, 0, 0, 0]\n","            if bboxes is not None and len(bboxes) > 0:\n","                bboxes = sorted(bboxes, key=lambda x: x[4], reverse=True)\n","                x1, y1, x2, y2, _ = bboxes[0]\n","                pred_box = [x1, y1, x2, y2]\n","\n","            gt_box = annotations.get(image_key, [0, 0, 0, 0])\n","\n","            if gt_box == [0, 0, 0, 0]:\n","                print(f\"[WARNING] Không tìm thấy ground truth cho {image_key}\")\n","\n","            iou = compute_iou(pred_box, gt_box)\n","            center_distance = compute_center_distance(pred_box, gt_box)\n","\n","            records.append({\n","                \"file_name\": image_key,\n","                \"x1\": pred_box[0],\n","                \"y1\": pred_box[1],\n","                \"x2\": pred_box[2],\n","                \"y2\": pred_box[3],\n","                \"IoU\": round(iou, 4),\n","                \"center_distance\": round(center_distance, 2),\n","                \"inference_time\": round(inference_time, 4)\n","            })\n","\n","    return pd.DataFrame(records)\n","\n","# ===================== PHẦN 4: CHẠY ĐÁNH GIÁ =====================\n","\n","def evaluate_face_detection(image_folder, det_model_path, annotation_file, output_csv):\n","    \"\"\"Đánh giá phát hiện khuôn mặt với RetinaFace và lưu kết quả vào CSV\"\"\"\n","    results_df = process_images(image_folder, det_model_path, annotation_file)\n","    results_df.to_csv(output_csv, index=False)\n","    print(f\"[INFO] Đã lưu kết quả vào {output_csv}\")\n"],"metadata":{"id":"ikxMB4JPh1Bw","executionInfo":{"status":"ok","timestamp":1745377753848,"user_tz":-420,"elapsed":25,"user":{"displayName":"Huệ Trần Thị Thanh","userId":"01694173941333005562"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["image_folder = \"/content/drive/MyDrive/Report/data/image_customer\"\n","det_model_path = \"/content/drive/MyDrive/Report/model/det_10g.onnx\"\n","annotation_file = \"/content/drive/MyDrive/Report/data/annotations.xml\"\n","output_csv = \"/content/drive/MyDrive/Report/result/RetinaFace_face_detection.csv\"\n","\n","evaluate_face_detection(image_folder, det_model_path, annotation_file, output_csv)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OZ46ZLcyrWUB","executionInfo":{"status":"ok","timestamp":1745377887435,"user_tz":-420,"elapsed":129950,"user":{"displayName":"Huệ Trần Thị Thanh","userId":"01694173941333005562"}},"outputId":"1da3e803-6afb-4780-9845-3717577463ec"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n","[INFO] Đã lưu kết quả vào /content/drive/MyDrive/Report/result/RetinaFace_face_detection.csv\n"]}]}]}